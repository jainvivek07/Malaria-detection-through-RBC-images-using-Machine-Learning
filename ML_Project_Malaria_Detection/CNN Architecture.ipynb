{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9efcbe4",
   "metadata": {
    "id": "c9efcbe4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9817c612",
   "metadata": {
    "id": "9817c612"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def metric(y_test, y_pred):\n",
    "    matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    return matrix,accuracy,precision,recall,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kXul5zyA8zw8",
   "metadata": {
    "id": "kXul5zyA8zw8"
   },
   "source": [
    "<h1>Steps to load data from drive to google collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81geZQBwyVrX",
   "metadata": {
    "id": "81geZQBwyVrX"
   },
   "outputs": [],
   "source": [
    "os.mkdir(\"dataset\")\n",
    "os.mkdir(\"dataset/train\")\n",
    "os.mkdir(\"dataset/test\")\n",
    "os.mkdir(\"dataset/train/parasite\")\n",
    "os.mkdir(\"dataset/test/parasite\")\n",
    "os.mkdir(\"dataset/train/uninfected\")\n",
    "os.mkdir(\"dataset/test/uninfected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "434bf49a",
   "metadata": {
    "id": "434bf49a"
   },
   "outputs": [],
   "source": [
    "def move_files(abs_dirname, train_dir, test_dir):\n",
    "    \"\"\"Move files into subdirectories.\"\"\"\n",
    "\n",
    "    files = [os.path.join(abs_dirname, f) for f in os.listdir(abs_dirname)]\n",
    "\n",
    "    i = 0\n",
    "    curr_subdir = None\n",
    "    files.sort()\n",
    "\n",
    "    for f in files:\n",
    "        # create new subdir if necessary\n",
    "        if i == 0:\n",
    "            curr_subdir = train_dir\n",
    "        \n",
    "        if i == 11025:\n",
    "            curr_subdir = test_dir\n",
    "\n",
    "        # move file to current dir\n",
    "        f_base = os.path.basename(f)\n",
    "        shutil.copy(f, os.path.join(curr_subdir, f_base))\n",
    "        i += 1\n",
    "        if(i%1000 == 0):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8b8cd76",
   "metadata": {
    "id": "a8b8cd76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "abs_dirname = \"cell_images/Parasitized/\"\n",
    "train_dir = \"dataset/train/parasite\"\n",
    "test_dir = \"dataset/test/parasite\"\n",
    "move_files(abs_dirname, train_dir, test_dir)\n",
    "\n",
    "print(type(abs_dirname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd23f1ea",
   "metadata": {
    "id": "dd23f1ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n"
     ]
    }
   ],
   "source": [
    "abs_dirname = \"cell_images/Uninfected/\"\n",
    "train_dir = \"dataset/train/uninfected\"\n",
    "test_dir = \"dataset/test/uninfected\"\n",
    "move_files(abs_dirname, train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78c1e0a2",
   "metadata": {
    "id": "78c1e0a2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(columns = [\"path\", \"label\"])\n",
    "test_df = pd.DataFrame(columns = [\"path\", \"label\"])\n",
    "\n",
    "abs_dirname  = \"dataset/train/parasite\"\n",
    "files = [os.path.join(abs_dirname, f) for f in os.listdir(abs_dirname)]\n",
    "\n",
    "for f in files:\n",
    "    f_base = os.path.basename(f)\n",
    "    if f_base.endswith('.png'):\n",
    "        df = pd.DataFrame({'path': [f_base], 'label': [1]})\n",
    "        train_df = pd.concat([train_df, df], ignore_index=True)\n",
    "\n",
    "abs_dirname  = \"dataset/train/uninfected\"\n",
    "files = [os.path.join(abs_dirname, f) for f in os.listdir(abs_dirname)]\n",
    "for f in files:\n",
    "    f_base = os.path.basename(f)\n",
    "    if f_base.endswith('.png'):\n",
    "        df = pd.DataFrame({'path': [f_base], 'label': [0]})\n",
    "        train_df = pd.concat([train_df, df], ignore_index=True)\n",
    "    \n",
    "train_df.to_csv(\"dataset/train.csv\", index = False)\n",
    "\n",
    "abs_dirname  = \"dataset/test/parasite\"\n",
    "files = [os.path.join(abs_dirname, f) for f in os.listdir(abs_dirname)]\n",
    "for f in files:\n",
    "    f_base = os.path.basename(f)\n",
    "    if f_base.endswith('.png'):\n",
    "        df = pd.DataFrame({'path': [f_base], 'label': [1]})\n",
    "        test_df = pd.concat([test_df, df], ignore_index=True)\n",
    "    \n",
    "abs_dirname  = \"dataset/test/uninfected\"\n",
    "files = [os.path.join(abs_dirname, f) for f in os.listdir(abs_dirname)]\n",
    "for f in files:\n",
    "    f_base = os.path.basename(f)\n",
    "    if f_base.endswith('.png'):\n",
    "        df = pd.DataFrame({'path': [f_base], 'label': [0]})\n",
    "        test_df = pd.concat([test_df, df], ignore_index=True)\n",
    "    \n",
    "test_df.to_csv(\"dataset/test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98d92989",
   "metadata": {
    "id": "98d92989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11016\n"
     ]
    }
   ],
   "source": [
    "test_df\n",
    "print(test_df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EVqq57HO88kg",
   "metadata": {
    "id": "EVqq57HO88kg"
   },
   "source": [
    "<h1>Creating dataloader for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c424884e",
   "metadata": {
    "id": "c424884e"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.img_labels['label'][idx]\n",
    "        class_type = \"parasite\" if label == 1 else \"uninfected\"\n",
    "        img_path = os.path.join(self.img_dir, class_type, self.img_labels.iloc[idx, 0])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (32, 32))\n",
    "        image = np.moveaxis(image, -1, 0)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image.astype(np.float32)/255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93b44415",
   "metadata": {
    "id": "93b44415"
   },
   "outputs": [],
   "source": [
    "train_dir = \"dataset/train\"\n",
    "test_dir = \"dataset/test\"\n",
    "train_csv_path = \"dataset/train.csv\"\n",
    "test_csv_path = \"dataset/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649f972",
   "metadata": {
    "id": "c649f972"
   },
   "source": [
    "<h1>CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "753c1807",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "753c1807",
    "outputId": "741ec951-4d03-49d7-c682-1adc9e19507b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e59fa85",
   "metadata": {
    "id": "9e59fa85"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00104c55",
   "metadata": {
    "id": "00104c55"
   },
   "outputs": [],
   "source": [
    "##train and test dataloader\n",
    "training_data = CustomImageDataset(annotations_file=train_csv_path, img_dir= train_dir)\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "testing_data = CustomImageDataset(annotations_file=test_csv_path, img_dir= test_dir)\n",
    "test_loader = DataLoader(testing_data, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2AKtgwnm6Jy5",
   "metadata": {
    "id": "2AKtgwnm6Jy5"
   },
   "outputs": [],
   "source": [
    "#Dataframe to store accuracy\n",
    "train_accuracy_df = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall','F1'], index = ['VGG11'])\n",
    "test_accuracy_df = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall','F1'], index = ['VGG11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab199ed0",
   "metadata": {
    "id": "ab199ed0"
   },
   "outputs": [],
   "source": [
    "# clas for CNN architecture\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, cnn_type, in_channels=3, num_classes=1):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.cnn_type = cnn_type\n",
    "        self.VGG_types = {'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],}\n",
    "        self.conv_layers = self.create_conv_layers(self.VGG_types[self.cnn_type])\n",
    "        \n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "        \n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "                \n",
    "                layers += [nn.Conv2d(in_channels=in_channels,out_channels=out_channels,\n",
    "                                     kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU()]\n",
    "                in_channels = x\n",
    "            elif x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n",
    "                \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "yeq_CG4P1-5k",
   "metadata": {
    "id": "yeq_CG4P1-5k"
   },
   "outputs": [],
   "source": [
    "#Function to train the model\n",
    "def train(cnn_type, check):\n",
    "  model = ConvNet(cnn_type = cnn_type).to(device)\n",
    "  PATH = f'./{model.cnn_type}.pth'\n",
    "  if(check == 'save'):\n",
    "    pass\n",
    "  elif check == 'load':\n",
    "    print(\"Model already present\")\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "  model.train()\n",
    "  criterion = nn.BCELoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "  loss_plot = []\n",
    "  for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "      images = images.to(device)\n",
    "      labels = labels.unsqueeze(1)\n",
    "      labels = labels.float()\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "     # Backward and optimize\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if (i+1) % 64 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')\n",
    "        loss_plot.append(loss.item())\n",
    "    print('Model saved after epoch: ', epoch)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    \n",
    "  print('Finished Training Completely')\n",
    "  torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "351994db",
   "metadata": {
    "id": "351994db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to evaluate the test dataset\n",
    "def test(data_loader, model):\n",
    "  with torch.no_grad():\n",
    "    y_pred = []\n",
    "    y_hat = []\n",
    "    for images, labels in data_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        y_pred.extend(outputs)\n",
    "        y_hat.extend(labels)\n",
    "  y_pred = np.array(y_pred).flatten()\n",
    "  y_hat = np.array(y_hat).flatten()\n",
    "  y_pred =  np.where(y_pred>=0.5, 1, 0) \n",
    "  return metric(y_hat, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cdbaa1bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdbaa1bb",
    "outputId": "44adff96-dfcd-4dec-b078-b357064ccf56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.689884\n",
      "Model saved after epoch:  0\n",
      "Epoch [2/100], Loss: 0.532565\n",
      "Model saved after epoch:  1\n",
      "Epoch [3/100], Loss: 0.232001\n",
      "Model saved after epoch:  2\n",
      "Epoch [4/100], Loss: 0.141270\n",
      "Model saved after epoch:  3\n",
      "Epoch [5/100], Loss: 0.122403\n",
      "Model saved after epoch:  4\n",
      "Epoch [6/100], Loss: 0.109334\n",
      "Model saved after epoch:  5\n",
      "Epoch [7/100], Loss: 0.151461\n",
      "Model saved after epoch:  6\n",
      "Epoch [8/100], Loss: 0.118564\n",
      "Model saved after epoch:  7\n",
      "Epoch [9/100], Loss: 0.060867\n",
      "Model saved after epoch:  8\n",
      "Epoch [10/100], Loss: 0.147612\n",
      "Model saved after epoch:  9\n",
      "Epoch [11/100], Loss: 0.080366\n",
      "Model saved after epoch:  10\n",
      "Epoch [12/100], Loss: 0.160371\n",
      "Model saved after epoch:  11\n",
      "Epoch [13/100], Loss: 0.127296\n",
      "Model saved after epoch:  12\n",
      "Epoch [14/100], Loss: 0.104681\n",
      "Model saved after epoch:  13\n",
      "Epoch [15/100], Loss: 0.052756\n",
      "Model saved after epoch:  14\n",
      "Epoch [16/100], Loss: 0.091756\n",
      "Model saved after epoch:  15\n",
      "Epoch [17/100], Loss: 0.133449\n",
      "Model saved after epoch:  16\n",
      "Epoch [18/100], Loss: 0.083083\n",
      "Model saved after epoch:  17\n",
      "Epoch [19/100], Loss: 0.065721\n",
      "Model saved after epoch:  18\n",
      "Epoch [20/100], Loss: 0.046930\n",
      "Model saved after epoch:  19\n",
      "Epoch [21/100], Loss: 0.062881\n",
      "Model saved after epoch:  20\n",
      "Epoch [22/100], Loss: 0.068597\n",
      "Model saved after epoch:  21\n",
      "Epoch [23/100], Loss: 0.073679\n",
      "Model saved after epoch:  22\n",
      "Epoch [24/100], Loss: 0.071703\n",
      "Model saved after epoch:  23\n",
      "Epoch [25/100], Loss: 0.043752\n",
      "Model saved after epoch:  24\n",
      "Epoch [26/100], Loss: 0.074283\n",
      "Model saved after epoch:  25\n",
      "Epoch [27/100], Loss: 0.108684\n",
      "Model saved after epoch:  26\n",
      "Epoch [28/100], Loss: 0.052209\n",
      "Model saved after epoch:  27\n",
      "Epoch [29/100], Loss: 0.069101\n",
      "Model saved after epoch:  28\n",
      "Epoch [30/100], Loss: 0.043080\n",
      "Model saved after epoch:  29\n",
      "Epoch [31/100], Loss: 0.046668\n",
      "Model saved after epoch:  30\n",
      "Epoch [32/100], Loss: 0.035619\n",
      "Model saved after epoch:  31\n",
      "Epoch [33/100], Loss: 0.034302\n",
      "Model saved after epoch:  32\n",
      "Epoch [34/100], Loss: 0.065060\n",
      "Model saved after epoch:  33\n",
      "Epoch [35/100], Loss: 0.051523\n",
      "Model saved after epoch:  34\n",
      "Epoch [36/100], Loss: 0.014990\n",
      "Model saved after epoch:  35\n",
      "Epoch [37/100], Loss: 0.033861\n",
      "Model saved after epoch:  36\n",
      "Epoch [38/100], Loss: 0.019017\n",
      "Model saved after epoch:  37\n",
      "Epoch [39/100], Loss: 0.009114\n",
      "Model saved after epoch:  38\n",
      "Epoch [40/100], Loss: 0.032271\n",
      "Model saved after epoch:  39\n",
      "Epoch [41/100], Loss: 0.035322\n",
      "Model saved after epoch:  40\n",
      "Epoch [42/100], Loss: 0.020253\n",
      "Model saved after epoch:  41\n",
      "Epoch [43/100], Loss: 0.013175\n",
      "Model saved after epoch:  42\n",
      "Epoch [44/100], Loss: 0.003536\n",
      "Model saved after epoch:  43\n",
      "Epoch [45/100], Loss: 0.047867\n",
      "Model saved after epoch:  44\n",
      "Epoch [46/100], Loss: 0.017722\n",
      "Model saved after epoch:  45\n",
      "Epoch [47/100], Loss: 0.034104\n",
      "Model saved after epoch:  46\n",
      "Epoch [48/100], Loss: 0.013142\n",
      "Model saved after epoch:  47\n",
      "Epoch [49/100], Loss: 0.062950\n",
      "Model saved after epoch:  48\n",
      "Epoch [50/100], Loss: 0.000789\n",
      "Model saved after epoch:  49\n",
      "Epoch [51/100], Loss: 0.009116\n",
      "Model saved after epoch:  50\n",
      "Epoch [52/100], Loss: 0.010745\n",
      "Model saved after epoch:  51\n",
      "Epoch [53/100], Loss: 0.017702\n",
      "Model saved after epoch:  52\n",
      "Epoch [54/100], Loss: 0.012384\n",
      "Model saved after epoch:  53\n",
      "Epoch [55/100], Loss: 0.001942\n",
      "Model saved after epoch:  54\n",
      "Epoch [56/100], Loss: 0.013830\n",
      "Model saved after epoch:  55\n",
      "Epoch [57/100], Loss: 0.020126\n",
      "Model saved after epoch:  56\n",
      "Epoch [58/100], Loss: 0.002193\n",
      "Model saved after epoch:  57\n",
      "Epoch [59/100], Loss: 0.006719\n",
      "Model saved after epoch:  58\n",
      "Epoch [60/100], Loss: 0.015494\n",
      "Model saved after epoch:  59\n",
      "Epoch [61/100], Loss: 0.012292\n",
      "Model saved after epoch:  60\n",
      "Epoch [62/100], Loss: 0.001123\n",
      "Model saved after epoch:  61\n",
      "Epoch [63/100], Loss: 0.002322\n",
      "Model saved after epoch:  62\n",
      "Epoch [64/100], Loss: 0.001479\n",
      "Model saved after epoch:  63\n",
      "Epoch [65/100], Loss: 0.006971\n",
      "Model saved after epoch:  64\n",
      "Epoch [66/100], Loss: 0.011276\n",
      "Model saved after epoch:  65\n",
      "Epoch [67/100], Loss: 0.006325\n",
      "Model saved after epoch:  66\n",
      "Epoch [68/100], Loss: 0.001691\n",
      "Model saved after epoch:  67\n",
      "Epoch [69/100], Loss: 0.061524\n",
      "Model saved after epoch:  68\n",
      "Epoch [70/100], Loss: 0.023756\n",
      "Model saved after epoch:  69\n",
      "Epoch [71/100], Loss: 0.001250\n",
      "Model saved after epoch:  70\n",
      "Epoch [72/100], Loss: 0.004572\n",
      "Model saved after epoch:  71\n",
      "Epoch [73/100], Loss: 0.022799\n",
      "Model saved after epoch:  72\n",
      "Epoch [74/100], Loss: 0.000133\n",
      "Model saved after epoch:  73\n",
      "Epoch [75/100], Loss: 0.002606\n",
      "Model saved after epoch:  74\n",
      "Epoch [76/100], Loss: 0.026746\n",
      "Model saved after epoch:  75\n",
      "Epoch [77/100], Loss: 0.000513\n",
      "Model saved after epoch:  76\n",
      "Epoch [78/100], Loss: 0.009174\n",
      "Model saved after epoch:  77\n",
      "Epoch [79/100], Loss: 0.001941\n",
      "Model saved after epoch:  78\n",
      "Epoch [80/100], Loss: 0.006918\n",
      "Model saved after epoch:  79\n",
      "Epoch [81/100], Loss: 0.007301\n",
      "Model saved after epoch:  80\n",
      "Epoch [82/100], Loss: 0.025997\n",
      "Model saved after epoch:  81\n",
      "Epoch [83/100], Loss: 0.019996\n",
      "Model saved after epoch:  82\n",
      "Epoch [84/100], Loss: 0.000362\n",
      "Model saved after epoch:  83\n",
      "Epoch [85/100], Loss: 0.016569\n",
      "Model saved after epoch:  84\n",
      "Epoch [86/100], Loss: 0.003063\n",
      "Model saved after epoch:  85\n",
      "Epoch [87/100], Loss: 0.000531\n",
      "Model saved after epoch:  86\n",
      "Epoch [88/100], Loss: 0.001321\n",
      "Model saved after epoch:  87\n",
      "Epoch [89/100], Loss: 0.000022\n",
      "Model saved after epoch:  88\n",
      "Epoch [90/100], Loss: 0.004534\n",
      "Model saved after epoch:  89\n",
      "Epoch [91/100], Loss: 0.003234\n",
      "Model saved after epoch:  90\n",
      "Epoch [92/100], Loss: 0.004640\n",
      "Model saved after epoch:  91\n",
      "Epoch [93/100], Loss: 0.000129\n",
      "Model saved after epoch:  92\n",
      "Epoch [94/100], Loss: 0.001379\n",
      "Model saved after epoch:  93\n",
      "Epoch [95/100], Loss: 0.001191\n",
      "Model saved after epoch:  94\n",
      "Epoch [96/100], Loss: 0.000579\n",
      "Model saved after epoch:  95\n",
      "Epoch [97/100], Loss: 0.006830\n",
      "Model saved after epoch:  96\n",
      "Epoch [98/100], Loss: 0.000057\n",
      "Model saved after epoch:  97\n",
      "Epoch [99/100], Loss: 0.000040\n",
      "Model saved after epoch:  98\n",
      "Epoch [100/100], Loss: 0.035543\n",
      "Model saved after epoch:  99\n",
      "Finished Training Completely\n"
     ]
    }
   ],
   "source": [
    "train('VGG11', check = 'save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dg4GvERECH5v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg4GvERECH5v",
    "outputId": "d9b2d38e-214a-460f-9123-0c7b0efa6e6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet(cnn_type = 'VGG11').to(device)\n",
    "PATH = f'./VGG11.pth' \n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c37f65d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c37f65d3",
    "outputId": "81c758c1-2fdc-4cea-d601-133583f61833"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2533,  221],\n",
       "       [ 108, 2646]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix, accuracy, precision, recall, f1 = test(test_loader, model)\n",
    "test_accuracy_df.loc['VGG11'] = [accuracy,precision,recall,f1]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4816f4ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4816f4ff",
    "outputId": "3a10a746-47d8-4c30-af9b-84a5958c7237"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10988,    37],\n",
       "       [    9, 11016]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix, accuracy, precision, recall, f1 = test(train_loader, model)\n",
    "train_accuracy_df.loc['VGG11'] = [accuracy,precision,recall,f1]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VGG11</th>\n",
       "      <td>0.940269</td>\n",
       "      <td>0.922916</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.941469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy Precision    Recall        F1\n",
       "VGG11  0.940269  0.922916  0.960784  0.941469"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VGG11</th>\n",
       "      <td>0.997914</td>\n",
       "      <td>0.996652</td>\n",
       "      <td>0.999184</td>\n",
       "      <td>0.997916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy Precision    Recall        F1\n",
       "VGG11  0.997914  0.996652  0.999184  0.997916"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vgg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
